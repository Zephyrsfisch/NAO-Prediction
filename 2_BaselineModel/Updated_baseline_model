Improved Model: Random Forest with Feature Engineering
This approach adds:

Lag Features: Values from 1, 2, 3, and 12 months ago to capture short-term persistence and yearly seasonality.

Random Forest: A robust non-linear model that generally beats basic ARIMA for this type of noisy time series.

Expected Results:

RMSE: Should drop below 0.50 (beating both Climatology and SARIMA).

ACC (Correlation): Should increase significantly above 0.37.

Python

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from math import sqrt

# 1. Load Data
url = "https://ftp.cpc.ncep.noaa.gov/cwlinks/norm.daily.nao.cdas.z500.19500101_current.csv"
try:
    df = pd.read_csv(url)
except Exception as e:
    print(f"Error loading data: {e}")
    # If URL fails, load from local if available or check internet connection

# 2. Preprocessing (Matching your notebook)
df['time'] = pd.to_datetime(df[['year', 'month', 'day']])
df = df.set_index('time')

# Resample to monthly mean
df_monthly = df[['nao_index_cdas']].resample('M').mean()

# 3. Feature Engineering (The Improvement)
# Add seasonality
df_monthly['month_num'] = df_monthly.index.month

# Add Lag features (past values) to capture autocorrelation
# Lag 1-3 for persistence, Lag 12 for annual cycle
for lag in [1, 2, 3, 6, 12]:
    df_monthly[f'lag_{lag}'] = df_monthly['nao_index_cdas'].shift(lag)

# Drop NaNs created by shifting
df_model = df_monthly.dropna()

# 4. Train/Test Split (90/10 split as in your baseline)
split_idx = int(len(df_model) * 0.9)
train = df_model.iloc[:split_idx]
test = df_model.iloc[split_idx:]

features = ['month_num', 'lag_1', 'lag_2', 'lag_3', 'lag_6', 'lag_12']
target = 'nao_index_cdas'

X_train = train[features]
y_train = train[target]
X_test = test[features]
y_test = test[target]

# 5. Model Training: Random Forest
rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)
rf.fit(X_train, y_train)

# 6. Prediction & Evaluation
predictions = rf.predict(X_test)

# Calculate Scores
mse_rf = mean_squared_error(y_test, predictions)
rmse_rf = sqrt(mse_rf)
# ACC is typically the Pearson Correlation in this context
acc_rf = np.corrcoef(y_test, predictions)[0, 1]

print("------ UPDATED SCORES (Random Forest) ------")
print(f"RMSE RF: {rmse_rf:.4f} (Goal: < 0.5026)")
print(f"ACC RF:  {acc_rf:.4f} (Goal: > 0.3695)")

# Compare with simple Persistence (Lag 1) to verify skill
rmse_pers = sqrt(mean_squared_error(y_test, X_test['lag_1']))
print(f"RMSE Persistence (Lag 1): {rmse_pers:.4f}")
Why this improves your baseline:
Beating Climatology: Your current notebook results show Climatology (RMSE 0.50) beating SARIMA (RMSE 0.62). Climatology simply predicts the historical average for that month. By adding lag_1 (last month's value) and lag_12 (last year's value) as features, the Random Forest can adjust that average based on the current state of the climate, reducing error.

Handling Seasonality: Instead of forcing a rigid seasonal structure like SARIMA, the Random Forest learns how the seasonal signal (month_num) interacts with recent anomalies (lag_1).
